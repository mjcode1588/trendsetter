{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import matplotlib.pyplot as plt # 득점모델 변수 중요도\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "train_df.drop([ 'X_02', 'X_48', 'X_47', 'X_23', 'X_11', 'X_10', 'X_04'], inplace= True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./test.csv')\n",
    "test_df.drop([ 'X_02', 'X_48', 'X_47', 'X_23', 'X_11', 'X_10', 'X_04'], inplace= True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.filter(regex='X') # Input : X Featrue\n",
    "train_y = train_df.filter(regex='Y') # Output : Y_01 Feature..\n",
    "test_x = test_df.filter(regex='X')\n",
    "test_y = test_df.filter(regex='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12048\\4133901488.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_x.drop([\"X_01\",\"X_05\", \"X_06\"],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_0506 = train_x[[\"X_01\",\"X_05\", \"X_06\"]]\n",
    "\n",
    "train_x.drop([\"X_01\",\"X_05\", \"X_06\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_pca = train_x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80271132, -0.81190089,  1.94079365],\n",
       "       [ 0.4186678 , -0.71707028,  1.03805543],\n",
       "       [ 1.57042184,  1.48774146,  1.03805543],\n",
       "       ...,\n",
       "       [ 0.03462428,  1.47132847, -0.76697848],\n",
       "       [-0.73308623, -0.56935336, -1.21790507],\n",
       "       [-0.73308623, -0.60765034, -0.31560937]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_0506 = StandardScaler().fit_transform(X_0506)\n",
    "X_0506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "train_x_pca = StandardScaler().fit_transform(train_x_pca)\n",
    "train_x_pca\n",
    "\n",
    "test_x = StandardScaler().fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f\"{i+1}comp\" for i in range(20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "printcipalComponents = pca.fit_transform(test_x)\n",
    "principalDf_test = pd.DataFrame(data=printcipalComponents, columns = [columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>1comp</th>\n",
       "      <th>2comp</th>\n",
       "      <th>3comp</th>\n",
       "      <th>4comp</th>\n",
       "      <th>5comp</th>\n",
       "      <th>6comp</th>\n",
       "      <th>7comp</th>\n",
       "      <th>8comp</th>\n",
       "      <th>9comp</th>\n",
       "      <th>10comp</th>\n",
       "      <th>11comp</th>\n",
       "      <th>12comp</th>\n",
       "      <th>13comp</th>\n",
       "      <th>14comp</th>\n",
       "      <th>15comp</th>\n",
       "      <th>16comp</th>\n",
       "      <th>17comp</th>\n",
       "      <th>18comp</th>\n",
       "      <th>19comp</th>\n",
       "      <th>20comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.436566</td>\n",
       "      <td>4.710954</td>\n",
       "      <td>-1.855503</td>\n",
       "      <td>-1.414837</td>\n",
       "      <td>-1.748719</td>\n",
       "      <td>2.164066</td>\n",
       "      <td>0.369192</td>\n",
       "      <td>-2.800608</td>\n",
       "      <td>0.575261</td>\n",
       "      <td>-0.734410</td>\n",
       "      <td>0.157660</td>\n",
       "      <td>1.396420</td>\n",
       "      <td>0.537878</td>\n",
       "      <td>-0.307805</td>\n",
       "      <td>0.327642</td>\n",
       "      <td>-0.745886</td>\n",
       "      <td>-0.635644</td>\n",
       "      <td>-0.237257</td>\n",
       "      <td>-0.567266</td>\n",
       "      <td>0.505395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.779547</td>\n",
       "      <td>0.092615</td>\n",
       "      <td>-0.088363</td>\n",
       "      <td>-0.283825</td>\n",
       "      <td>-1.695752</td>\n",
       "      <td>4.253543</td>\n",
       "      <td>-0.745466</td>\n",
       "      <td>0.147308</td>\n",
       "      <td>-0.994428</td>\n",
       "      <td>-0.619127</td>\n",
       "      <td>-0.403261</td>\n",
       "      <td>-0.060816</td>\n",
       "      <td>-2.538296</td>\n",
       "      <td>-0.098348</td>\n",
       "      <td>0.853662</td>\n",
       "      <td>0.548809</td>\n",
       "      <td>-2.120763</td>\n",
       "      <td>-0.037303</td>\n",
       "      <td>-0.274749</td>\n",
       "      <td>0.062189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.508064</td>\n",
       "      <td>4.214491</td>\n",
       "      <td>4.784464</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>4.392253</td>\n",
       "      <td>2.060011</td>\n",
       "      <td>1.043084</td>\n",
       "      <td>-3.374774</td>\n",
       "      <td>2.979237</td>\n",
       "      <td>2.326346</td>\n",
       "      <td>0.264732</td>\n",
       "      <td>1.475042</td>\n",
       "      <td>-0.725043</td>\n",
       "      <td>1.286428</td>\n",
       "      <td>0.627961</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>1.080300</td>\n",
       "      <td>-1.238633</td>\n",
       "      <td>-0.560678</td>\n",
       "      <td>-0.629712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.285359</td>\n",
       "      <td>-0.299613</td>\n",
       "      <td>3.318644</td>\n",
       "      <td>-0.615289</td>\n",
       "      <td>4.486654</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>1.078411</td>\n",
       "      <td>-1.761645</td>\n",
       "      <td>1.199562</td>\n",
       "      <td>2.052726</td>\n",
       "      <td>-1.030580</td>\n",
       "      <td>0.883128</td>\n",
       "      <td>1.306684</td>\n",
       "      <td>0.266206</td>\n",
       "      <td>-0.973037</td>\n",
       "      <td>0.849579</td>\n",
       "      <td>0.209249</td>\n",
       "      <td>-0.071391</td>\n",
       "      <td>0.274970</td>\n",
       "      <td>0.274636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.111183</td>\n",
       "      <td>-0.058474</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>-1.229148</td>\n",
       "      <td>4.693326</td>\n",
       "      <td>-0.715815</td>\n",
       "      <td>2.432648</td>\n",
       "      <td>-0.902155</td>\n",
       "      <td>2.671164</td>\n",
       "      <td>2.122978</td>\n",
       "      <td>-0.426695</td>\n",
       "      <td>1.509762</td>\n",
       "      <td>-0.846648</td>\n",
       "      <td>2.247473</td>\n",
       "      <td>-0.643578</td>\n",
       "      <td>-0.179733</td>\n",
       "      <td>1.146332</td>\n",
       "      <td>0.558958</td>\n",
       "      <td>-0.183709</td>\n",
       "      <td>-0.148968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39603</th>\n",
       "      <td>1.604237</td>\n",
       "      <td>-1.029964</td>\n",
       "      <td>1.031996</td>\n",
       "      <td>0.699881</td>\n",
       "      <td>1.305525</td>\n",
       "      <td>-2.055710</td>\n",
       "      <td>-0.408280</td>\n",
       "      <td>0.616008</td>\n",
       "      <td>0.206361</td>\n",
       "      <td>-1.569305</td>\n",
       "      <td>-0.073917</td>\n",
       "      <td>-2.217954</td>\n",
       "      <td>3.757912</td>\n",
       "      <td>0.400607</td>\n",
       "      <td>3.048684</td>\n",
       "      <td>0.402167</td>\n",
       "      <td>-1.572520</td>\n",
       "      <td>1.360379</td>\n",
       "      <td>-0.475813</td>\n",
       "      <td>0.040478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39604</th>\n",
       "      <td>-0.365162</td>\n",
       "      <td>-3.257503</td>\n",
       "      <td>1.664414</td>\n",
       "      <td>2.262617</td>\n",
       "      <td>1.127567</td>\n",
       "      <td>-0.421384</td>\n",
       "      <td>0.798729</td>\n",
       "      <td>0.466455</td>\n",
       "      <td>-0.616229</td>\n",
       "      <td>-2.436966</td>\n",
       "      <td>-0.150190</td>\n",
       "      <td>-1.746120</td>\n",
       "      <td>2.518842</td>\n",
       "      <td>1.810159</td>\n",
       "      <td>4.174802</td>\n",
       "      <td>0.392215</td>\n",
       "      <td>-0.032047</td>\n",
       "      <td>-0.077307</td>\n",
       "      <td>-0.708214</td>\n",
       "      <td>-0.133525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39605</th>\n",
       "      <td>1.665671</td>\n",
       "      <td>-0.304092</td>\n",
       "      <td>1.984697</td>\n",
       "      <td>0.842646</td>\n",
       "      <td>1.706856</td>\n",
       "      <td>-1.563013</td>\n",
       "      <td>-0.471065</td>\n",
       "      <td>-0.111005</td>\n",
       "      <td>0.908237</td>\n",
       "      <td>-1.423499</td>\n",
       "      <td>-0.108108</td>\n",
       "      <td>-1.857655</td>\n",
       "      <td>1.725990</td>\n",
       "      <td>1.216999</td>\n",
       "      <td>3.439076</td>\n",
       "      <td>-1.745869</td>\n",
       "      <td>-1.329120</td>\n",
       "      <td>1.969393</td>\n",
       "      <td>-0.134444</td>\n",
       "      <td>0.941569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39606</th>\n",
       "      <td>2.476032</td>\n",
       "      <td>0.188780</td>\n",
       "      <td>1.246322</td>\n",
       "      <td>1.450950</td>\n",
       "      <td>1.270004</td>\n",
       "      <td>-1.199476</td>\n",
       "      <td>-0.502526</td>\n",
       "      <td>0.984431</td>\n",
       "      <td>-0.113305</td>\n",
       "      <td>-1.374071</td>\n",
       "      <td>-0.304341</td>\n",
       "      <td>-1.847860</td>\n",
       "      <td>2.949078</td>\n",
       "      <td>1.051644</td>\n",
       "      <td>3.288950</td>\n",
       "      <td>-0.628003</td>\n",
       "      <td>-1.868932</td>\n",
       "      <td>0.495139</td>\n",
       "      <td>-0.539230</td>\n",
       "      <td>-0.714766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39607</th>\n",
       "      <td>1.384160</td>\n",
       "      <td>-1.035018</td>\n",
       "      <td>-1.187311</td>\n",
       "      <td>0.694574</td>\n",
       "      <td>2.472794</td>\n",
       "      <td>-0.457398</td>\n",
       "      <td>-0.301201</td>\n",
       "      <td>0.724199</td>\n",
       "      <td>-0.099481</td>\n",
       "      <td>-1.507481</td>\n",
       "      <td>0.428963</td>\n",
       "      <td>-1.421644</td>\n",
       "      <td>2.918066</td>\n",
       "      <td>0.469031</td>\n",
       "      <td>3.345360</td>\n",
       "      <td>-0.969190</td>\n",
       "      <td>-2.051597</td>\n",
       "      <td>0.721330</td>\n",
       "      <td>-0.634412</td>\n",
       "      <td>0.086095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39608 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1comp     2comp     3comp     4comp     5comp     6comp     7comp  \\\n",
       "0      4.436566  4.710954 -1.855503 -1.414837 -1.748719  2.164066  0.369192   \n",
       "1     -0.779547  0.092615 -0.088363 -0.283825 -1.695752  4.253543 -0.745466   \n",
       "2      3.508064  4.214491  4.784464  0.865462  4.392253  2.060011  1.043084   \n",
       "3     -0.285359 -0.299613  3.318644 -0.615289  4.486654  0.797753  1.078411   \n",
       "4      1.111183 -0.058474  0.445400 -1.229148  4.693326 -0.715815  2.432648   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39603  1.604237 -1.029964  1.031996  0.699881  1.305525 -2.055710 -0.408280   \n",
       "39604 -0.365162 -3.257503  1.664414  2.262617  1.127567 -0.421384  0.798729   \n",
       "39605  1.665671 -0.304092  1.984697  0.842646  1.706856 -1.563013 -0.471065   \n",
       "39606  2.476032  0.188780  1.246322  1.450950  1.270004 -1.199476 -0.502526   \n",
       "39607  1.384160 -1.035018 -1.187311  0.694574  2.472794 -0.457398 -0.301201   \n",
       "\n",
       "          8comp     9comp    10comp    11comp    12comp    13comp    14comp  \\\n",
       "0     -2.800608  0.575261 -0.734410  0.157660  1.396420  0.537878 -0.307805   \n",
       "1      0.147308 -0.994428 -0.619127 -0.403261 -0.060816 -2.538296 -0.098348   \n",
       "2     -3.374774  2.979237  2.326346  0.264732  1.475042 -0.725043  1.286428   \n",
       "3     -1.761645  1.199562  2.052726 -1.030580  0.883128  1.306684  0.266206   \n",
       "4     -0.902155  2.671164  2.122978 -0.426695  1.509762 -0.846648  2.247473   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39603  0.616008  0.206361 -1.569305 -0.073917 -2.217954  3.757912  0.400607   \n",
       "39604  0.466455 -0.616229 -2.436966 -0.150190 -1.746120  2.518842  1.810159   \n",
       "39605 -0.111005  0.908237 -1.423499 -0.108108 -1.857655  1.725990  1.216999   \n",
       "39606  0.984431 -0.113305 -1.374071 -0.304341 -1.847860  2.949078  1.051644   \n",
       "39607  0.724199 -0.099481 -1.507481  0.428963 -1.421644  2.918066  0.469031   \n",
       "\n",
       "         15comp    16comp    17comp    18comp    19comp    20comp  \n",
       "0      0.327642 -0.745886 -0.635644 -0.237257 -0.567266  0.505395  \n",
       "1      0.853662  0.548809 -2.120763 -0.037303 -0.274749  0.062189  \n",
       "2      0.627961 -0.119840  1.080300 -1.238633 -0.560678 -0.629712  \n",
       "3     -0.973037  0.849579  0.209249 -0.071391  0.274970  0.274636  \n",
       "4     -0.643578 -0.179733  1.146332  0.558958 -0.183709 -0.148968  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "39603  3.048684  0.402167 -1.572520  1.360379 -0.475813  0.040478  \n",
       "39604  4.174802  0.392215 -0.032047 -0.077307 -0.708214 -0.133525  \n",
       "39605  3.439076 -1.745869 -1.329120  1.969393 -0.134444  0.941569  \n",
       "39606  3.288950 -0.628003 -1.868932  0.495139 -0.539230 -0.714766  \n",
       "39607  3.345360 -0.969190 -2.051597  0.721330 -0.634412  0.086095  \n",
       "\n",
       "[39608 rows x 20 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f\"{i+1}comp\" for i in range(20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "printcipalComponents = pca.fit_transform(train_x_pca)\n",
    "principalDf = pd.DataFrame(data=printcipalComponents, columns = [columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_run_Ro = RandomForestRegressor(random_state=0, max_depth=30, min_samples_leaf=16, n_estimators=200)\n",
    "LR_Ro = MultiOutputRegressor(rf_run_Ro).fit(principalDf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE':1.015100032629558\n"
     ]
    }
   ],
   "source": [
    "train_predict = LR_Ro.predict(principalDf)\n",
    "print(\"RMSE':{}\".format(math.sqrt(mean_squared_error(train_predict, train_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = LR_Ro.predict(principalDf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "for idx, col in enumerate(submit.columns):\n",
    "    if col=='ID':\n",
    "        continue\n",
    "    submit[col] = pred[:,idx-1]\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12433913, 0.09375041, 0.08831654, 0.07483545, 0.04751895,\n",
       "       0.03933579, 0.03864118, 0.03679977, 0.02778849, 0.02609538])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.597421081141726"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but PCA is expecting 49 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\open\\trendsetter\\mjcode\\pca_rf.ipynb 셀 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/open/trendsetter/mjcode/pca_rf.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pcscore \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mtransform(X_0506)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_base.py:120\u001b[0m, in \u001b[0;36m_BasePCA.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m\"\"\"Apply dimensionality reduction to X.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[39mX is projected on the first principal components previously extracted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39m    is the number of samples and `n_components` is the number of the components.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     X \u001b[39m=\u001b[39m X \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 3 features, but PCA is expecting 49 features as input."
     ]
    }
   ],
   "source": [
    "pcscore = pca.transform(X_0506)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.09277124, 4.59388623, 4.32761964, 3.6670295 , 2.3284872 ,\n",
       "       1.92750241, 1.89346539, 1.8032344 , 1.36167019, 1.2787059 ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./rfpca_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
