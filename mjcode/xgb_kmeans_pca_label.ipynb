{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import matplotlib.pyplot as plt # 득점모델 변수 중요도\n",
    "import xgboost\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train데이터 불러오기\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop([ 'X_48', 'X_47', 'X_23', 'X_11', 'X_10', 'X_04'], inplace= True, axis=1)\n",
    "test_df.drop([ 'X_48', 'X_47', 'X_23', 'X_11', 'X_10', 'X_04'], inplace= True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.filter(regex='X') # Input : X Featrue\n",
    "train_y = train_df.filter(regex='Y') # Output : Y_01 Feature..\n",
    "test_x = test_df.filter(regex='X')\n",
    "test_y = test_df.filter(regex='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=5, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=5, random_state=0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, random_state=0) # K-means\n",
    "kmeans.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmm_cluster_labels_tr = kmeans.predict(train_x)\n",
    "kmm_cluster_labels_te = kmeans.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16264\\641694845.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_x[\"km_label\"] = kmm_cluster_labels_tr\n"
     ]
    }
   ],
   "source": [
    "train_x[\"km_label\"] = kmm_cluster_labels_tr\n",
    "test_x[\"km_label\"] = kmm_cluster_labels_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_list = [['X_01','X_02','X_05','X_06'],['X_14','X_15','X_16','X_17','X_18'],['X_19','X_20','X_21','X_22'],['X_30','X_31','X_32','X_33'],['X_24','X_25','X_26','X_27','X_28','X_29'],['X_50','X_51','X_52','X_53','X_54','X_55','X_56']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "train_col = train_x.columns\n",
    "train_x = MaxAbsScaler().fit_transform(train_x)\n",
    "train_x = pd.DataFrame(data = train_x, columns=train_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "cnt = 1\n",
    "pca_result = []\n",
    "for i in pca_list:\n",
    "    pca_x = train_x[i]\n",
    "    printcipalComponents = pca.fit_transform(pca_x)\n",
    "    pca_result.append(printcipalComponents)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt =1\n",
    "for i in pca_result:\n",
    "    train_x[f\"{cnt}_X_comp\"] = i\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pca_list:\n",
    "    train_x.drop(i, inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_34</th>\n",
       "      <th>X_35</th>\n",
       "      <th>X_36</th>\n",
       "      <th>X_37</th>\n",
       "      <th>X_38</th>\n",
       "      <th>X_39</th>\n",
       "      <th>X_40</th>\n",
       "      <th>X_41</th>\n",
       "      <th>X_42</th>\n",
       "      <th>X_43</th>\n",
       "      <th>X_44</th>\n",
       "      <th>X_45</th>\n",
       "      <th>X_46</th>\n",
       "      <th>X_49</th>\n",
       "      <th>km_label</th>\n",
       "      <th>1_X_comp</th>\n",
       "      <th>2_X_comp</th>\n",
       "      <th>3_X_comp</th>\n",
       "      <th>4_X_comp</th>\n",
       "      <th>5_X_comp</th>\n",
       "      <th>6_X_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.756645</td>\n",
       "      <td>0.179727</td>\n",
       "      <td>0.026128</td>\n",
       "      <td>0.385433</td>\n",
       "      <td>0.966592</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.993119</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.984721</td>\n",
       "      <td>0.993119</td>\n",
       "      <td>-0.509153</td>\n",
       "      <td>-0.957285</td>\n",
       "      <td>-0.961061</td>\n",
       "      <td>0.980574</td>\n",
       "      <td>0.979011</td>\n",
       "      <td>0.993928</td>\n",
       "      <td>0.989212</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>0.084722</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.049706</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>-0.048706</td>\n",
       "      <td>0.068281</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.045718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730851</td>\n",
       "      <td>0.175333</td>\n",
       "      <td>0.025647</td>\n",
       "      <td>0.366453</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.987768</td>\n",
       "      <td>0.983193</td>\n",
       "      <td>0.984721</td>\n",
       "      <td>0.988532</td>\n",
       "      <td>-0.498294</td>\n",
       "      <td>-0.942657</td>\n",
       "      <td>-0.944695</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.980877</td>\n",
       "      <td>0.988323</td>\n",
       "      <td>0.991088</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>0.090984</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>-0.087367</td>\n",
       "      <td>0.060577</td>\n",
       "      <td>0.032691</td>\n",
       "      <td>-0.034541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718515</td>\n",
       "      <td>0.175821</td>\n",
       "      <td>0.044303</td>\n",
       "      <td>0.426987</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.991590</td>\n",
       "      <td>0.983193</td>\n",
       "      <td>0.983193</td>\n",
       "      <td>0.993884</td>\n",
       "      <td>-0.501396</td>\n",
       "      <td>-0.946167</td>\n",
       "      <td>-0.945824</td>\n",
       "      <td>0.977336</td>\n",
       "      <td>0.980877</td>\n",
       "      <td>0.988790</td>\n",
       "      <td>0.990619</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.999319</td>\n",
       "      <td>0.095567</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.055924</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>-0.083788</td>\n",
       "      <td>0.064730</td>\n",
       "      <td>-0.010557</td>\n",
       "      <td>-0.017229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757766</td>\n",
       "      <td>0.176492</td>\n",
       "      <td>0.048257</td>\n",
       "      <td>0.400571</td>\n",
       "      <td>0.964365</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.987003</td>\n",
       "      <td>0.990833</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>0.987768</td>\n",
       "      <td>-0.497983</td>\n",
       "      <td>-0.937975</td>\n",
       "      <td>-0.940745</td>\n",
       "      <td>0.979648</td>\n",
       "      <td>0.978545</td>\n",
       "      <td>0.990191</td>\n",
       "      <td>0.989212</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130993</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.073251</td>\n",
       "      <td>0.008751</td>\n",
       "      <td>-0.090252</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>-0.051817</td>\n",
       "      <td>-0.069514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.712908</td>\n",
       "      <td>0.181130</td>\n",
       "      <td>0.043302</td>\n",
       "      <td>0.378767</td>\n",
       "      <td>0.968820</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.981665</td>\n",
       "      <td>0.986249</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>-0.504189</td>\n",
       "      <td>-0.949678</td>\n",
       "      <td>-0.950903</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.989257</td>\n",
       "      <td>0.989681</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096462</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>-0.081160</td>\n",
       "      <td>0.074656</td>\n",
       "      <td>0.026664</td>\n",
       "      <td>-0.034411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39602</th>\n",
       "      <td>0.698329</td>\n",
       "      <td>0.184304</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.467537</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.985474</td>\n",
       "      <td>0.993125</td>\n",
       "      <td>0.988541</td>\n",
       "      <td>0.986239</td>\n",
       "      <td>-0.499224</td>\n",
       "      <td>-0.944997</td>\n",
       "      <td>-0.947517</td>\n",
       "      <td>0.979186</td>\n",
       "      <td>0.983209</td>\n",
       "      <td>0.989724</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529232</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.043568</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>-0.055259</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.043025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39603</th>\n",
       "      <td>0.703936</td>\n",
       "      <td>0.178262</td>\n",
       "      <td>0.042828</td>\n",
       "      <td>0.424587</td>\n",
       "      <td>0.979955</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.984709</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.984721</td>\n",
       "      <td>0.983180</td>\n",
       "      <td>-0.487124</td>\n",
       "      <td>-0.921006</td>\n",
       "      <td>-0.925508</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.983675</td>\n",
       "      <td>0.990659</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.992512</td>\n",
       "      <td>0.530390</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.044246</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>-0.068477</td>\n",
       "      <td>0.023085</td>\n",
       "      <td>0.011815</td>\n",
       "      <td>0.038635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39604</th>\n",
       "      <td>0.725244</td>\n",
       "      <td>0.182839</td>\n",
       "      <td>0.042979</td>\n",
       "      <td>0.310703</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.992355</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.979358</td>\n",
       "      <td>-0.500155</td>\n",
       "      <td>-0.947338</td>\n",
       "      <td>-0.948081</td>\n",
       "      <td>0.979186</td>\n",
       "      <td>0.983675</td>\n",
       "      <td>0.991126</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.993193</td>\n",
       "      <td>0.076930</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.010414</td>\n",
       "      <td>-0.001309</td>\n",
       "      <td>-0.043088</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>0.003487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39605</th>\n",
       "      <td>0.714029</td>\n",
       "      <td>0.184914</td>\n",
       "      <td>0.047163</td>\n",
       "      <td>0.432195</td>\n",
       "      <td>0.964365</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.987003</td>\n",
       "      <td>0.985485</td>\n",
       "      <td>0.990069</td>\n",
       "      <td>0.991590</td>\n",
       "      <td>-0.507602</td>\n",
       "      <td>-0.957285</td>\n",
       "      <td>-0.957675</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.981810</td>\n",
       "      <td>0.988323</td>\n",
       "      <td>0.991088</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543125</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.037317</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>-0.053361</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>-0.045697</td>\n",
       "      <td>0.025362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39606</th>\n",
       "      <td>0.736458</td>\n",
       "      <td>0.184060</td>\n",
       "      <td>0.047289</td>\n",
       "      <td>0.433042</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.993884</td>\n",
       "      <td>0.987777</td>\n",
       "      <td>0.988541</td>\n",
       "      <td>0.983945</td>\n",
       "      <td>-0.495191</td>\n",
       "      <td>-0.937975</td>\n",
       "      <td>-0.939616</td>\n",
       "      <td>0.979186</td>\n",
       "      <td>0.983209</td>\n",
       "      <td>0.989257</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.995235</td>\n",
       "      <td>0.542687</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.023484</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>-0.002172</td>\n",
       "      <td>-0.022171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39607 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X_03      X_07      X_08      X_09      X_12      X_13      X_34  \\\n",
       "0      0.756645  0.179727  0.026128  0.385433  0.966592  0.642857  0.993119   \n",
       "1      0.730851  0.175333  0.025647  0.366453  0.975501  0.642857  0.987768   \n",
       "2      0.718515  0.175821  0.044303  0.426987  0.971047  0.535714  0.991590   \n",
       "3      0.757766  0.176492  0.048257  0.400571  0.964365  0.750000  0.987003   \n",
       "4      0.712908  0.181130  0.043302  0.378767  0.968820  0.571429  0.990826   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39602  0.698329  0.184304  0.032600  0.467537  0.971047  0.535714  0.985474   \n",
       "39603  0.703936  0.178262  0.042828  0.424587  0.979955  0.464286  0.984709   \n",
       "39604  0.725244  0.182839  0.042979  0.310703  0.975501  0.500000  0.992355   \n",
       "39605  0.714029  0.184914  0.047163  0.432195  0.964365  0.571429  0.987003   \n",
       "39606  0.736458  0.184060  0.047289  0.433042  0.975501  0.500000  0.993884   \n",
       "\n",
       "           X_35      X_36      X_37      X_38      X_39      X_40      X_41  \\\n",
       "0      0.983957  0.984721  0.993119 -0.509153 -0.957285 -0.961061  0.980574   \n",
       "1      0.983193  0.984721  0.988532 -0.498294 -0.942657 -0.944695  0.978723   \n",
       "2      0.983193  0.983193  0.993884 -0.501396 -0.946167 -0.945824  0.977336   \n",
       "3      0.990833  0.992361  0.987768 -0.497983 -0.937975 -0.940745  0.979648   \n",
       "4      0.981665  0.986249  0.990826 -0.504189 -0.949678 -0.950903  0.978723   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39602  0.993125  0.988541  0.986239 -0.499224 -0.944997 -0.947517  0.979186   \n",
       "39603  0.983957  0.984721  0.983180 -0.487124 -0.921006 -0.925508  0.978723   \n",
       "39604  0.991597  0.991597  0.979358 -0.500155 -0.947338 -0.948081  0.979186   \n",
       "39605  0.985485  0.990069  0.991590 -0.507602 -0.957285 -0.957675  0.978261   \n",
       "39606  0.987777  0.988541  0.983945 -0.495191 -0.937975 -0.939616  0.979186   \n",
       "\n",
       "           X_42      X_43      X_44      X_45      X_46      X_49  km_label  \\\n",
       "0      0.979011  0.993928  0.989212  0.690476  0.995916  0.084722      1.00   \n",
       "1      0.980877  0.988323  0.991088  0.309524  0.995916  0.090984      1.00   \n",
       "2      0.980877  0.988790  0.990619  0.333333  0.999319  0.095567      1.00   \n",
       "3      0.978545  0.990191  0.989212  0.523810  1.000000  0.130993      0.25   \n",
       "4      0.977612  0.989257  0.989681  0.523810  1.000000  0.096462      1.00   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39602  0.983209  0.989724  0.993902  0.261905  1.000000  0.529232      0.50   \n",
       "39603  0.983675  0.990659  0.993902  0.285714  0.992512  0.530390      0.50   \n",
       "39604  0.983675  0.991126  0.993902  0.309524  0.993193  0.076930      1.00   \n",
       "39605  0.981810  0.988323  0.991088  0.261905  1.000000  0.543125      0.50   \n",
       "39606  0.983209  0.989257  0.993902  0.261905  0.995235  0.542687      0.50   \n",
       "\n",
       "       1_X_comp  2_X_comp  3_X_comp  4_X_comp  5_X_comp  6_X_comp  \n",
       "0      0.049706  0.004100 -0.048706  0.068281 -0.000818 -0.045718  \n",
       "1      0.026225  0.004316 -0.087367  0.060577  0.032691 -0.034541  \n",
       "2      0.055924  0.004721 -0.083788  0.064730 -0.010557 -0.017229  \n",
       "3      0.073251  0.008751 -0.090252  0.060200 -0.051817 -0.069514  \n",
       "4      0.012401  0.005503 -0.081160  0.074656  0.026664 -0.034411  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "39602 -0.043568 -0.002210 -0.055259  0.002287  0.002174  0.043025  \n",
       "39603 -0.044246  0.001723 -0.068477  0.023085  0.011815  0.038635  \n",
       "39604 -0.010414 -0.001309 -0.043088  0.005659 -0.007737  0.003487  \n",
       "39605 -0.037317  0.000460 -0.053361  0.000516 -0.045697  0.025362  \n",
       "39606 -0.023484 -0.002067 -0.072806  0.015862 -0.002172 -0.022171  \n",
       "\n",
       "[39607 rows x 27 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgboost.XGBRegressor(n_estimators=1000, max_depth=8, learning_rate=0.01, n_jobs=-1, gamma= 0.2)\n",
    "XGB_Ro = MultiOutputRegressor(xgb_model).fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE':0.9875602094019984\n"
     ]
    }
   ],
   "source": [
    "train_predict = XGB_Ro.predict(train_x)\n",
    "print(\"RMSE':{}\".format(math.sqrt(mean_squared_error(train_predict, train_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_01</th>\n",
       "      <th>Y_02</th>\n",
       "      <th>Y_03</th>\n",
       "      <th>Y_04</th>\n",
       "      <th>Y_05</th>\n",
       "      <th>Y_06</th>\n",
       "      <th>Y_07</th>\n",
       "      <th>Y_08</th>\n",
       "      <th>Y_09</th>\n",
       "      <th>Y_10</th>\n",
       "      <th>Y_11</th>\n",
       "      <th>Y_12</th>\n",
       "      <th>Y_13</th>\n",
       "      <th>Y_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "      <td>39607.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.353738</td>\n",
       "      <td>1.057186</td>\n",
       "      <td>1.013930</td>\n",
       "      <td>13.620820</td>\n",
       "      <td>31.289715</td>\n",
       "      <td>16.529505</td>\n",
       "      <td>3.154878</td>\n",
       "      <td>-26.293493</td>\n",
       "      <td>-26.307240</td>\n",
       "      <td>-22.398647</td>\n",
       "      <td>24.324202</td>\n",
       "      <td>-26.236397</td>\n",
       "      <td>-26.232510</td>\n",
       "      <td>-26.244503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.111639</td>\n",
       "      <td>0.113362</td>\n",
       "      <td>0.099489</td>\n",
       "      <td>0.914789</td>\n",
       "      <td>0.647926</td>\n",
       "      <td>1.250627</td>\n",
       "      <td>0.121274</td>\n",
       "      <td>0.218666</td>\n",
       "      <td>0.211159</td>\n",
       "      <td>0.374380</td>\n",
       "      <td>0.212436</td>\n",
       "      <td>0.213067</td>\n",
       "      <td>0.213664</td>\n",
       "      <td>0.213853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.274870</td>\n",
       "      <td>0.376155</td>\n",
       "      <td>0.264732</td>\n",
       "      <td>8.518718</td>\n",
       "      <td>24.420166</td>\n",
       "      <td>-18.060017</td>\n",
       "      <td>1.302985</td>\n",
       "      <td>-27.663937</td>\n",
       "      <td>-27.823275</td>\n",
       "      <td>-29.113297</td>\n",
       "      <td>21.875595</td>\n",
       "      <td>-27.926640</td>\n",
       "      <td>-27.891256</td>\n",
       "      <td>-27.935921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.288805</td>\n",
       "      <td>0.990806</td>\n",
       "      <td>0.955835</td>\n",
       "      <td>13.112654</td>\n",
       "      <td>30.994278</td>\n",
       "      <td>16.503779</td>\n",
       "      <td>3.089638</td>\n",
       "      <td>-26.436066</td>\n",
       "      <td>-26.440026</td>\n",
       "      <td>-22.511211</td>\n",
       "      <td>24.219540</td>\n",
       "      <td>-26.369656</td>\n",
       "      <td>-26.366773</td>\n",
       "      <td>-26.377220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.357230</td>\n",
       "      <td>1.060588</td>\n",
       "      <td>1.018527</td>\n",
       "      <td>13.559438</td>\n",
       "      <td>31.331554</td>\n",
       "      <td>16.593073</td>\n",
       "      <td>3.163359</td>\n",
       "      <td>-26.282793</td>\n",
       "      <td>-26.303246</td>\n",
       "      <td>-22.322666</td>\n",
       "      <td>24.321226</td>\n",
       "      <td>-26.229940</td>\n",
       "      <td>-26.227076</td>\n",
       "      <td>-26.237484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.422984</td>\n",
       "      <td>1.124801</td>\n",
       "      <td>1.073437</td>\n",
       "      <td>14.070251</td>\n",
       "      <td>31.650058</td>\n",
       "      <td>16.691635</td>\n",
       "      <td>3.219131</td>\n",
       "      <td>-26.170855</td>\n",
       "      <td>-26.194941</td>\n",
       "      <td>-22.198818</td>\n",
       "      <td>24.428722</td>\n",
       "      <td>-26.120354</td>\n",
       "      <td>-26.116181</td>\n",
       "      <td>-26.127979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.703909</td>\n",
       "      <td>2.642728</td>\n",
       "      <td>2.150704</td>\n",
       "      <td>79.915024</td>\n",
       "      <td>34.676643</td>\n",
       "      <td>17.813843</td>\n",
       "      <td>4.223561</td>\n",
       "      <td>-24.469006</td>\n",
       "      <td>-24.792166</td>\n",
       "      <td>-20.797062</td>\n",
       "      <td>25.754976</td>\n",
       "      <td>-24.635752</td>\n",
       "      <td>-24.555773</td>\n",
       "      <td>-24.356871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Y_01          Y_02          Y_03          Y_04          Y_05  \\\n",
       "count  39607.000000  39607.000000  39607.000000  39607.000000  39607.000000   \n",
       "mean       1.353738      1.057186      1.013930     13.620820     31.289715   \n",
       "std        0.111639      0.113362      0.099489      0.914789      0.647926   \n",
       "min        0.274870      0.376155      0.264732      8.518718     24.420166   \n",
       "25%        1.288805      0.990806      0.955835     13.112654     30.994278   \n",
       "50%        1.357230      1.060588      1.018527     13.559438     31.331554   \n",
       "75%        1.422984      1.124801      1.073437     14.070251     31.650058   \n",
       "max        2.703909      2.642728      2.150704     79.915024     34.676643   \n",
       "\n",
       "               Y_06          Y_07          Y_08          Y_09          Y_10  \\\n",
       "count  39607.000000  39607.000000  39607.000000  39607.000000  39607.000000   \n",
       "mean      16.529505      3.154878    -26.293493    -26.307240    -22.398647   \n",
       "std        1.250627      0.121274      0.218666      0.211159      0.374380   \n",
       "min      -18.060017      1.302985    -27.663937    -27.823275    -29.113297   \n",
       "25%       16.503779      3.089638    -26.436066    -26.440026    -22.511211   \n",
       "50%       16.593073      3.163359    -26.282793    -26.303246    -22.322666   \n",
       "75%       16.691635      3.219131    -26.170855    -26.194941    -22.198818   \n",
       "max       17.813843      4.223561    -24.469006    -24.792166    -20.797062   \n",
       "\n",
       "               Y_11          Y_12          Y_13          Y_14  \n",
       "count  39607.000000  39607.000000  39607.000000  39607.000000  \n",
       "mean      24.324202    -26.236397    -26.232510    -26.244503  \n",
       "std        0.212436      0.213067      0.213664      0.213853  \n",
       "min       21.875595    -27.926640    -27.891256    -27.935921  \n",
       "25%       24.219540    -26.369656    -26.366773    -26.377220  \n",
       "50%       24.321226    -26.229940    -26.227076    -26.237484  \n",
       "75%       24.428722    -26.120354    -26.116181    -26.127979  \n",
       "max       25.754976    -24.635752    -24.555773    -24.356871  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_predict,columns = train_y.columns).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fold = []\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "for train, test in kfold.split(train_x):\n",
    "    XGB = MultiOutputRegressor(xgb_model).fit(train_x.loc[train], train_y.loc[train])\n",
    "    train_predict = XGB.predict(train_x.loc[test])\n",
    "    scores = math.sqrt(mean_squared_error(train_predict, train_y.loc[test]))\n",
    "    loss_fold.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1968468203154572, 1.2109570822549804, 1.1965353319503536]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
